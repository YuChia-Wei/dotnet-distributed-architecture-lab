version: '3.8'

services:
  otel-collector-contrib:
    image: otel/opentelemetry-collector-contrib:0.113.0
    restart: always
    container_name: otel-collector-contrib
    command: [ "--config=/etc/otel-collector.yaml" ]
    volumes:
      - ./config/otel-collector-contrib-config.yaml:/etc/otel-collector.yaml
    ports:
      - "4317:4317"
      - "4318:4318"
      - "8889"

  tempo:
    image: grafana/tempo:2.3.0
    container_name: tempo
    command: [ "-config.file=/etc/tempo.yaml" ]
    volumes:
      - ./config/tempo.yaml:/etc/tempo.yaml
    #      - ./tempo-data:/tmp/tempo
    ports:
      - "3200"   # tempo
      - "4317"  # otlp grpc
      - "4318"  # otlp http

  # 以下參考 grafana loki 範例與其他 github 中找到的範本
  # via: https://github.com/grafana/loki/blob/main/examples/getting-started/docker-compose.yaml
  # via: https://github.com/mnadeem/boot-opentelemetry-tempo/blob/main/docker-compose.yaml
  loki:
    container_name: loki
    image: grafana/loki:3.5.3
    command: -config.file=/etc/loki/config.yaml
    ports:
      - 3102:3100
      - 9095:9095
    volumes:
      - ./config/loki-local.yaml:/etc/loki/config.yaml

  prometheus:
    container_name: prometheus
    image: prom/prometheus:v2.53.0
    command:
      - --config.file=/etc/prometheus.yaml
      - --web.enable-remote-write-receiver
      - --enable-feature=exemplar-storage
    volumes:
      - ./config/prometheus.yaml:/etc/prometheus.yaml
    ports:
      - "9090:9090"
    depends_on:
      - otel-collector-contrib

  grafana:
    container_name: grafana
    image: grafana/grafana:11.1.0
    volumes:
      - ./config/grafana-datasources.yaml:/etc/grafana/provisioning/datasources/datasources.yaml
      - ./config/grafana-dashboards-provisioning:/etc/grafana/provisioning/dashboards
      - ./config/grafana-dashboards:/var/lib/grafana/dashboards
    environment:
      - GF_AUTH_ANONYMOUS_ENABLED=true
      - GF_AUTH_ANONYMOUS_ORG_ROLE=Admin
      - GF_AUTH_DISABLE_LOGIN_FORM=true
      - GF_FEATURE_TOGGLES_ENABLE=traceqlEditor tempoSearch tempoBackendSearch tempoApmTable
    ports:
      - "3000:3000"
    depends_on:
      - prometheus
      - tempo
      - loki

#  rabbitmq:
#    image: rabbitmq:4.1.2-management
#    container_name: rabbitmq
#    ports:
#      - "5672:5672"
#      - "15672:15672"
#    volumes:
#      - rabbitmq_data:/var/lib/rabbitmq/
#    environment:
#      - RABBITMQ_DEFAULT_USER=guest
#      - RABBITMQ_DEFAULT_PASS=guest

  # 改用官方 Apache Kafka（KRaft 單節點，同時擔任 controller 與 broker）
  kafka:
    image: apache/kafka:4.0.0
    container_name: kafka
    ports:
      - "9092:9092"     # 叢集內部/容器間
      - "29092:29092"   # 本機端工具
    volumes:
      # 官方映像的預設資料目錄建議掛載到 /var/lib/kafka/data
      - kafka_data:/var/lib/kafka/data
    environment:
      # --- KRaft（Kafka Raft）基本設定 ---
      - KAFKA_NODE_ID=1
      - KAFKA_PROCESS_ROLES=controller,broker
      - KAFKA_CONTROLLER_LISTENER_NAMES=CONTROLLER
      - KAFKA_CONTROLLER_QUORUM_VOTERS=1@kafka:9093

      # --- Listeners 與對外宣告（advertised listeners）---
      - KAFKA_LISTENERS=PLAINTEXT://:9092,CONTROLLER://:9093,PLAINTEXT_HOST://:29092
      - KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://kafka:9092,PLAINTEXT_HOST://localhost:29092
      - KAFKA_LISTENER_SECURITY_PROTOCOL_MAP=CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT

      # --- 單節點開發環境常見必要參數（避免內部主題無法建立）---
      - KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR=1
      - KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR=1
      - KAFKA_TRANSACTION_STATE_LOG_MIN_ISR=1

      # --- 資料目錄 ---
      - KAFKA_LOG_DIRS=/var/lib/kafka/data

      # --- KRaft 叢集 ID（cluster id）---
      # 單節點本機可固定一個；正式環境請事先用 kafka-storage.sh 產生並格式化
      - CLUSTER_ID=Lpaefz4gR4q_4Y-d-d-d-Q

  kafdrop:
    image: obsidiandynamics/kafdrop:latest
    container_name: kafdrop
    ports:
      - "19000:9000"
    environment:
      - KAFKA_BROKERCONNECT=kafka:9092
    depends_on:
      - kafka

  postgres-order:
    image: postgres:16-alpine
    container_name: postgres-order
    ports:
      - "5433:5432"
    volumes:
      - postgres_order_data:/var/lib/postgresql/data
      # copy the sql script to create tables
      - ./sql-script/create_orders_table.sql:/docker-entrypoint-initdb.d/create_orders_table.sql
    environment:
      - POSTGRES_USER=user
      - POSTGRES_PASSWORD=password
      - POSTGRES_DB=orders_db

  postgres-product:
    image: postgres:16-alpine
    container_name: postgres-product
    ports:
      - "5434:5432"
    volumes:
      - postgres_product_data:/var/lib/postgresql/data
      # copy the sql script to fill tables
      - ./sql-script/create_products_table.sql:/docker-entrypoint-initdb.d/create_products_table.sql
    environment:
      - POSTGRES_USER=user
      - POSTGRES_PASSWORD=password
      - POSTGRES_DB=products_db

  orders-api:
    build:
      context: ../src
      dockerfile: ../src/Order/Presentation/SaleOrders.WebApi/Dockerfile
    container_name: orders-api
    environment:
      - QUEUE_SERVICE=Kafka
#      - ConnectionStrings__MessageBroker=amqp://guest:guest@rabbitmq:5672
      - ConnectionStrings__KafkaBroker=kafka:9092
      - ConnectionStrings__DefaultConnection=User ID=user;Password=password;Host=postgres-order;Port=5432;Database=orders_db;Pooling=true;
      - OTEL_EXPORTER_OTLP_ENDPOINT=http://otel-collector-contrib:4317
      - OTEL_SERVICE_NAME=orders-api
    ports:
      - "8080:8080"
      - "8081:8081"
    depends_on:
      - otel-collector-contrib
#      - rabbitmq
      - postgres-order
      - kafka

  orders-consumer:
    build:
      context: ../src
      dockerfile: ../src/Order/Presentation/SaleOrders.Consumer/Dockerfile
    container_name: orders-consumer
    environment:
      - QUEUE_SERVICE=Kafka
#      - BrokerConnectionString=amqp://guest:guest@rabbitmq:5672
      - BrokerConnectionString=kafka:9092
      - OTEL_EXPORTER_OTLP_ENDPOINT=http://otel-collector-contrib:4317
      - OTEL_SERVICE_NAME=orders-consumer
    depends_on:
      - otel-collector-contrib
#      - rabbitmq
      - postgres-order
      - kafka

  product-api:
    build:
      context: ../src
      dockerfile: ../src/Product/Presentation/SaleProducts.WebApi/Dockerfile
    container_name: product-api
    environment:
      - QUEUE_SERVICE=Kafka
#      - ConnectionStrings__MessageBroker=amqp://guest:guest@rabbitmq:5672
      - ConnectionStrings__KafkaBroker=kafka:9092
      - ConnectionStrings__DefaultConnection=User ID=user;Password=password;Host=postgres-product;Port=5432;Database=products_db;Pooling=true;
      - OTEL_EXPORTER_OTLP_ENDPOINT=http://otel-collector-contrib:4317
      - OTEL_SERVICE_NAME=product-api
    ports:
      - "8090:8080"
      - "8091:8081"
    depends_on:
      - otel-collector-contrib
#      - rabbitmq
      - postgres-product
      - kafka

  product-consumer:
    build:
      context: ../src
      dockerfile: ../src/Product/Presentation/SaleProducts.Consumer/Dockerfile
    container_name: product-consumer
    environment:
      - QUEUE_SERVICE=Kafka
#      - BrokerConnectionString=amqp://guest:guest@rabbitmq:5672
      - BrokerConnectionString=kafka:9092
      - OTEL_EXPORTER_OTLP_ENDPOINT=http://otel-collector-contrib:4317
      - OTEL_SERVICE_NAME=product-consumer
      - ConnectionStrings__DefaultConnection=User ID=user;Password=password;Host=postgres-product;Port=5432;Database=products_db;Pooling=true;
    depends_on:
      - otel-collector-contrib
#      - rabbitmq
      - postgres-product
      - kafka

volumes:
#  rabbitmq_data:
  postgres_order_data:
  postgres_product_data:
  kafka_data:
