version: '3.8'

services:
  otel-collector:
    image: otel/opentelemetry-collector-contrib:0.106.1
    container_name: otel-collector
    command: ["--config=/etc/otel-collector-config.yaml"]
    volumes:
      - ./otel-collector-config.yaml:/etc/otel-collector-config.yaml:ro
    ports:
      - "4317:4317"   # OTLP gRPC receiver
      - "4318:4318"   # OTLP HTTP receiver
      - "9464:9464"   # Prometheus metrics exporter
  tempo:
    image: grafana/tempo:latest
    container_name: tempo
    command: ["-config.file=/etc/tempo.yaml"]
    volumes:
      - ./tempo.yaml:/etc/tempo.yaml:ro
    ports:
      - "3200:3200"
      - "4319:4317"
  loki:
    image: grafana/loki:2.9.8
    container_name: loki
    command: ["-config.file=/etc/loki-config.yaml"]
    volumes:
      - ./loki-config.yaml:/etc/loki-config.yaml:ro
    ports:
      - "3100:3100"
  prometheus:
    image: prom/prometheus:latest
    container_name: prometheus
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml:ro
    command:
      - --config.file=/etc/prometheus/prometheus.yml
    ports:
      - "9090:9090"
  grafana:
    image: grafana/grafana:latest
    container_name: grafana
    environment:
      - GF_SECURITY_ADMIN_USER=admin
      - GF_SECURITY_ADMIN_PASSWORD=admin
    volumes:
      - ./grafana/provisioning/datasources:/etc/grafana/provisioning/datasources
    ports:
      - "3000:3000"
    depends_on:
      - prometheus
      - tempo
      - loki
  rabbitmq:
    image: rabbitmq:4.1.2-management
    container_name: rabbitmq
    ports:
      - "5672:5672"
      - "15672:15672"
    volumes:
      - rabbitmq_data:/var/lib/rabbitmq/
    environment:
      - RABBITMQ_DEFAULT_USER=guest
      - RABBITMQ_DEFAULT_PASS=guest

  # 改用官方 Apache Kafka（KRaft 單節點，同時擔任 controller 與 broker）
  kafka:
    image: apache/kafka:4.0.0
    container_name: kafka
    ports:
      - "9092:9092"     # 叢集內部/容器間
      - "29092:29092"   # 本機端工具
    volumes:
      # 官方映像的預設資料目錄建議掛載到 /var/lib/kafka/data
      - kafka_data:/var/lib/kafka/data
    environment:
      # --- KRaft（Kafka Raft）基本設定 ---
      - KAFKA_NODE_ID=1
      - KAFKA_PROCESS_ROLES=controller,broker
      - KAFKA_CONTROLLER_LISTENER_NAMES=CONTROLLER
      - KAFKA_CONTROLLER_QUORUM_VOTERS=1@kafka:9093

      # --- Listeners 與對外宣告（advertised listeners）---
      - KAFKA_LISTENERS=PLAINTEXT://:9092,CONTROLLER://:9093,PLAINTEXT_HOST://:29092
      - KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://kafka:9092,PLAINTEXT_HOST://localhost:29092
      - KAFKA_LISTENER_SECURITY_PROTOCOL_MAP=CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT

      # --- 單節點開發環境常見必要參數（避免內部主題無法建立）---
      - KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR=1
      - KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR=1
      - KAFKA_TRANSACTION_STATE_LOG_MIN_ISR=1

      # --- 資料目錄 ---
      - KAFKA_LOG_DIRS=/var/lib/kafka/data

      # --- KRaft 叢集 ID（cluster id）---
      # 單節點本機可固定一個；正式環境請事先用 kafka-storage.sh 產生並格式化
      - CLUSTER_ID=Lpaefz4gR4q_4Y-d-d-d-Q

  kafdrop:
    image: obsidiandynamics/kafdrop:latest
    container_name: kafdrop
    ports:
      - "19000:9000"
    environment:
      - KAFKA_BROKERCONNECT=kafka:9092
    depends_on:
      - kafka

  postgres-order:
    image: postgres:16-alpine
    container_name: postgres-order
    ports:
      - "5433:5432"
    volumes:
      - postgres_order_data:/var/lib/postgresql/data
      # copy the sql script to create tables
      - ./sql-script/create_orders_table.sql:/docker-entrypoint-initdb.d/create_orders_table.sql
    environment:
      - POSTGRES_USER=user
      - POSTGRES_PASSWORD=password
      - POSTGRES_DB=orders_db

  postgres-product:
    image: postgres:16-alpine
    container_name: postgres-product
    ports:
      - "5434:5432"
    volumes:
      - postgres_product_data:/var/lib/postgresql/data
      # copy the sql script to fill tables
      - ./sql-script/create_products_table.sql:/docker-entrypoint-initdb.d/create_products_table.sql
    environment:
      - POSTGRES_USER=user
      - POSTGRES_PASSWORD=password
      - POSTGRES_DB=products_db

  orders-api:
    build:
      context: ../src
      dockerfile: ../src/Order/Presentation/SaleOrders.WebApi/Dockerfile
    container_name: orders-api
    environment:
      - QUEUE_SERVICE=Kafka
      - ConnectionStrings__MessageBroker=amqp://guest:guest@rabbitmq:5672
      - ConnectionStrings__KafkaBroker=kafka:9092
      - ConnectionStrings__DefaultConnection=User ID=user;Password=password;Host=postgres-order;Port=5432;Database=orders_db;Pooling=true;
      - OTEL_EXPORTER_OTLP_ENDPOINT=http://otel-collector:4317
      - OTEL_EXPORTER_OTLP_PROTOCOL=grpc
    ports:
      - "8080:8080"
      - "8081:8081"
    depends_on:
      - otel-collector
      - prometheus
      - tempo
      - loki
      - rabbitmq
      - postgres-order
      - kafka

  orders-consumer:
    build:
      context: ../src
      dockerfile: ../src/Order/Presentation/SaleOrders.Consumer/Dockerfile
    container_name: orders-consumer
    environment:
      - QUEUE_SERVICE=Kafka
#      - BrokerConnectionString=amqp://guest:guest@rabbitmq:5672
      - BrokerConnectionString=kafka:9092
      - OTEL_EXPORTER_OTLP_ENDPOINT=http://otel-collector:4317
      - OTEL_EXPORTER_OTLP_PROTOCOL=grpc
    depends_on:
      - otel-collector
      - prometheus
      - tempo
      - loki
      - rabbitmq
      - postgres-order
      - kafka

  product-api:
    build:
      context: ../src
      dockerfile: ../src/Product/Presentation/SaleProducts.WebApi/Dockerfile
    container_name: product-api
    environment:
      - QUEUE_SERVICE=Kafka
      - ConnectionStrings__MessageBroker=amqp://guest:guest@rabbitmq:5672
      - ConnectionStrings__KafkaBroker=kafka:9092
      - ConnectionStrings__DefaultConnection=User ID=user;Password=password;Host=postgres-product;Port=5432;Database=products_db;Pooling=true;
      - OTEL_EXPORTER_OTLP_ENDPOINT=http://otel-collector:4317
      - OTEL_EXPORTER_OTLP_PROTOCOL=grpc
    ports:
      - "8090:8080"
      - "8091:8081"
    depends_on:
      - otel-collector
      - prometheus
      - tempo
      - loki
      - rabbitmq
      - postgres-product
      - kafka

  product-consumer:
    build:
      context: ../src
      dockerfile: ../src/Product/Presentation/SaleProducts.Consumer/Dockerfile
    container_name: product-consumer
    environment:
      - QUEUE_SERVICE=Kafka
#      - BrokerConnectionString=amqp://guest:guest@rabbitmq:5672
      - BrokerConnectionString=kafka:9092
      - OTEL_EXPORTER_OTLP_ENDPOINT=http://otel-collector:4317
      - OTEL_EXPORTER_OTLP_PROTOCOL=grpc
    depends_on:
      - otel-collector
      - prometheus
      - tempo
      - loki
      - rabbitmq
      - postgres-product
      - kafka

volumes:
  rabbitmq_data:
  postgres_order_data:
  postgres_product_data:
  kafka_data:
